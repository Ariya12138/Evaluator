method_name: 'full_context'
model_name: 'qwen7b'
passage_type: 'top10_passages'
dataset_name: 'coral'
golden_dataset_path: '/home/qhj/yiruo/baselines/dataset/golden_response.json'
user_data_dir: "/home/qhj/yiruo/baselines/output/top10/real_raw_qwen7b"
save_dir: "/home/qhj/yiruo/evaluate/results"

gpu_id: "0,1,2,3"
save_intermediate_data: True
save_note: 'experiment'



# -------------------------------------------------Evaluation Settings------------------------------------------------#
# Metrics to evaluate the result
metrics: ['rouge-1','rouge-2', 'rouge-l', 'bleu-1','bleu-2', 'bleu-3', 'bleu-4', 'f1', 'recall', 'precision'] 
#metrics: ['rouge-1','rouge-2', 'rouge-l']
# Specify setting for metric, will be called within certain metrics
metric_setting: 
  retrieval_recall_topk: 5
  tokenizer_name: 'gpt-4'
save_metric_score: True #ã€€whether to save the metric score into txt file